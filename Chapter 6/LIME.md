# LIME

葡萄酒特征判断（预测好坏）

![image-20221224001609545](.\1.png)

图像分类正负向影响

![image-20221224001729500](.\2.png)

文本二分类（无神论/基督教）

![image-20221224001812193](.\3.png)

UCI判断收入数据集

![image-20221224001928529](.\4.png)

全称为Local Interpretable Model-Agnostic（通用） Explanations 发表于KDD2016

# 简介

只选取一个待测样本的邻域数据（越近权重更高），获取原模型预测结果（作为标签），训练线性模型（本身可解释）（或者决策树等等可解释性较好的模型）

![image-20221224002435547](.\5.png)

[LIME: explain Machine Learning predictions](https://towardsdatascience.com/lime-explain-machine-learning-predictions-af8f18189bfe)

![image-20221224002726452](.\6.png)

局部近似 -> 线性模型（通用范式，而非特殊算法）

可类比泰勒展开



![image-20221224002858614](.\7.png)

构造可解释特征作为人类的参考

预测结果相同 其思路可以判定模型优越性

![image-20221224005822525](.\21.png)

## 表格数据

![image-20221224003056081](.\8.png)

待测样本特征做扰动（数值类型）

扰动较小的权重更大（邻域）

![image-20221224003331213](.\9.png)

收入判定

## 图像数据

难点：待测样本如何进行扰动？

三通道 -> 像素层面扰动？

![image-20221224003528178](.\10.png)

改为聚类分块 对图块设置存在与否($2^n$个样本)

![image-20221224003554333](.\11.png)

输入到原始模型中得到预测结果

![image-20221224003633350](.\12.png)

邻域样本的可解释性特征+原始模型的标签训练线性模型

![image-20221224003941936](.\13.png)

流程如上(X'即为处理过的超像素图块)

![image-20221224004130144](.\14.png)

不同图块对模型预测的影响

![image-20221224004240737](.\15.png)

模型特征的bias(没有找到真正需要的特征)

![image-20221224004320263](.\16.png)

## 文本数据

词向量可解释性非常差（几千维几百维）

词袋模型，变为可解释特征

X到X‘：文本和图像的不同处理方式，变为可解释特征

![image-20221224004526151](.\17.png)

## 选取有代表性的样本

每一行代表一个邮件，每一列代表一个单词，选取两个样本却覆盖了四个特征

![image-20221224004803026](.\18.png)

## 实验

添加SP让人类来判断优劣(雪地 + 哈士奇 -> 狼)

![image-20221224005005867](.\19.png)

## 讨论

优点：

1. 兼容任意一种机器学习算法
2. 特征重要性：解释、理解、信赖
3. What-if场景：如果每个月多挣500元，额度是多少（灵敏度分析？）
4. 可解释单个样本预测结果、选取代表性样本
5. 可人工设计、构造可解释特征

缺点：

1. 人工设计、构造的“可解释特征”，不一定科学（最难的一步、最可以出彩的一步）
2. “局部线性”可能无法拟合原模型（局部都非线性？）
3. 不同样本，如何计算邻域权重
4. 每个待测样本都需训练对应可解释模型

# LIME改进

![image-20221224005604933](.\20.png)

不同半径不同预测结果（自适应半径，分配最适合的权重）

RBF Kernel:
$$
RBF(x^{i}) =exp(\frac{||x^{(i)}-x^{(ref)}||^2}{kw})
$$
