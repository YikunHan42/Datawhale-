# ZFNET

[Visualizing and Understanding Convolutional Networks](https://arxiv.org/pdf/1311.2901.pdf)

改变了Alexnet的参数，进行了小修小改

重点是**可视化技巧**

![image-20221216013640603](./1.png)

反池化

![image-20221216013757254](./2.png)

第1层卷积核 边缘颜色

第2层用上反卷积技巧

呈现对应关系

![image-20221216014040982](./3.png)

层数越深提取的体征越高级、越倾向于语义

![image-20221216014345974](./4.png)

## 特征演化

![image-20221216014630032](.\5.png)

横向表示训练的过程

低层收敛很快



计算feature vector欧式距离：

平移/缩放/旋转都会导致迅速扩大

![image-20221216014900377](.\6.png)



浅层 -> 显著差异(facial)

深层 -> 线性差异(semantic)



需要对卷积核进行大小裁剪

![image-20221216015255789](.\7.png)

第一层卷积核改小，步长改小



## 遮挡测试

### 敏感度分析

例：网络对于狗脸的关注

![image-20221216015445754](.\8.png)

中间图为使得同样fisher map最大化激活的其他图片（毛+文字+脸）

### 相关性分析

![image-20221216020037291](.\9.png)

遮挡差值即$epsilon$

如果对不同类型的狗遮挡同样位置基本一致，差值很小，则深度学习模型隐式地定义不同部位的相关性

## 模型效果

![image-20221216020332511](.\10.png)

既去掉卷积层，又去掉全连接层，误差非常大

![image-20221216020456983](.\11.png)

只改softmax分类层（微调和pretrain)，泛化效果非常好

![image-20221216020612214](.\12.png)

越深的层越有效（softmax/支持向量机验证）

![image-20221216020920984](.\13.png)

越深，information越discriminative